import { Steps } from "nextra/components";
import { CoAgentsEnterpriseCTA } from "@/components/coagents-enterprise-cta";
import SelfHostingCopilotRuntimeCreateEndpoint from "@/snippets/self-hosting-copilot-runtime-create-endpoint.mdx";

import { Tabs } from 'nextra/components';
import { Callout, Cards } from 'nextra/components';

import LlmAdapters from "@/snippets/llm-adapters.mdx";

# Getting started with CoAgents

LangGraph agents are written in Python, using the [LangGraph Python SDK](https://langchain-ai.github.io/langgraph/) and an API runtime server such as FastAPI. This guide presumes you're familiar with LangGraph and FastAPI, and are looking to use CopilotKit to build a great user experience for your AI agent.

To enable Python remote actions and connect your agent to CopilotKit, you'll need our Python SDK which you can install using `pip` (or your Python package manager of choice):

```bash
pip install copilotkit --extra-index-url https://copilotkit.gateway.scarf.sh/simple/
```

With `copilotkit` installed, update your FastAPI server to import what you will need to initialize the SDK as well as our FastAPI and LangGraph integrations:

```python filename="server.py" showLineNumbers
from fastapi import FastAPI
app = FastAPI()

# Import CopilotKit SDK and integrations
from copilotkit.integrations.fastapi import add_fastapi_endpoint
from copilotkit import CopilotKitSDK, LangGraphAgent

# Import your LangGraph agent; in this example, it's the variable
# named `basic_agent_app` in ./agent.py
from .agent import basic_agent_app

# Initialize the agent for use by CopilotKit; we'll name it "basic_agent"
basic_agent = LangGraphAgent(
    name="basic_agent",
    description="Agent that asks about the weather",
    agent=basic_agent_app,
)

# Next, initialize the SDK, passing in the agent
sdk = CopilotKitSDK(
    agents=[
        basic_agent
    ],
)

# Finally, add the remote actions endpoint to this API
add_fastapi_endpoint(app, sdk, "/copilotkit_remote")
```

Remember the name `basic_agent` as well as our API endpoint URL (`http://localhost:8000/copilotkit_remote`), we'll need them as we move on to integrating this agent into the frontend.

### Enabling remote agent actions in a Next.js app

#### Configure your LLM provider

<Tabs items={['OpenAI', 'Anthropic', 'Other LLM Providers']}>

<Tabs.Tab>

Create a `.env` file in the root of your project, if you haven't already, and add your OpenAI API key.

```plaintext filename=".env"
OPENAI_API_KEY=your_api_key_here
```

<Callout type="warning" title="Do you have a paid API key?">
  Please note that the code below uses GPT-4o, which requires a paid OpenAI API key.
  **If you are using a free OpenAI API key**, change the model to a different option such as "gpt-3.5-turbo".
</Callout>

Then create a new file called `src/lib/llmAdapter.ts`:

```ts filename="src/lib/llmAdapter.ts"
import OpenAI from 'openai';
import { OpenAIAdapter } from '@copilotkit/runtime';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const openaiAdapter = new OpenAIAdapter({ 
  openai,
  model: "gpt-4o"
});

export default openaiAdapter
```
</Tabs.Tab>

<Tabs.Tab>
Create a `.env` file in the root of your project, if you haven't already, and add your Anthropic API key.

```plaintext filename=".env"
ANTHROPIC_API_KEY=your_api_key_here
```

Then create a new file called `src/lib/llmAdapter.ts`:

```ts filename="src/lib/llmAdapter.ts"
import Anthropic from '@anthropic-ai/sdk';
import { AnthropicAdapter } from '@copilotkit/runtime';

const anthropic = new Anthropic({
  apiKey: 'my_api_key', // defaults to process.env["ANTHROPIC_API_KEY"]
});

const anthropicAdapter = new AnthropicAdapter({ anthropic });

export default anthropicAdapter
```
</Tabs.Tab>

<Tabs.Tab>

  To use a different LLM provider, you can follow the `OpenAI` instructions, but adapt them to use one of the other available LLM adapters listed below:

  <LlmAdapters />
</Tabs.Tab>

</Tabs>

#### Set up Copilot Runtime server route

Currently, you will need to self-host the CopilotRuntime route in order to use CoAgents. Support in Copilot Cloud is coming soon.

<Tabs items={['Next.js App Router', 'Next.js Pages Router', 'Node.js Express', 'Node.js HTTP', 'NestJS']}>

  {/* Next.js App Router */}
  <Tabs.Tab>
    Next, create a new server route which will make the `CopilotRuntime` available at `/api/copilotkit` and ready to work with remote actions provided by our Python app.
    
    Create a new file at `src/app/api/copilotkit/route.ts` and add this code:

    ```ts filename="app/api/copilotkit/route.ts" showLineNumbers
    import {
      CopilotRuntime,
      copilotRuntimeNextJSAppRouterEndpoint,
    } from '@copilotkit/runtime';
    import { NextRequest } from 'next/server';
    import serviceAdapter from '@/lib/llmAdapter';

    const runtime = new CopilotRuntime({
      remoteActions: [
        {
          url: `http://localhost:8000/copilotkit_remote`,
        }
      ]
    });

    export const POST = async (req: NextRequest) => {
      const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
        runtime,
        serviceAdapter,
        endpoint: '/api/copilotkit',
      });

      return handleRequest(req);
    };
    ```
  </Tabs.Tab>

  {/* Next.js Pages Router */}
  <Tabs.Tab>
    Next, create a new server route which will make the `CopilotRuntime` available at `/api/copilotkit` and ready to work with remote actions provided by our Python app.
    
    Create a new file at `src/pages/api/copilotkit.ts` and add this code:

    ```ts filename="pages/api/copilotkit.ts" showLineNumbers
    import { NextApiRequest, NextApiResponse } from 'next';
    import {
      CopilotRuntime,
      copilotRuntimeNextJSPagesRouterEndpoint,
    } from '@copilotkit/runtime';
    import serviceAdapter from '@/lib/llmAdapter';

    const handler = async (req: NextApiRequest, res: NextApiResponse) => {

      const runtime = new CopilotRuntime({
        remoteActions: [
          {
            url: `http://localhost:8000/copilotkit_remote`,
          }
        ]
      });

      const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
        runtime,
        serviceAdapter,
        endpoint: '/api/copilotkit',
      });

      return await handleRequest(req, res);
    };

    export default handler;
    ```
  </Tabs.Tab>

  {/* Node.js Express */}
  <Tabs.Tab>
    Next, create a new route handler which will make the `CopilotRuntime` available at `/copilotkit` and ready to work with remote actions provided by our Python app:

    ```ts filename="server.ts" showLineNumbers
    import express from 'express';
    import {
      CopilotRuntime,
      copilotRuntimeNodeHttpEndpoint,
    } from '@copilotkit/runtime';
    import llmAdapter from '@/lib/llmAdapter';

    const app = express();

    app.use('/copilotkit', (req, res, next) => {

      const runtime = new CopilotRuntime({
        remoteActions: [
          {
            url: `http://localhost:8000/copilotkit_remote`,
          }
        ]
      });
      
      const handler = copilotRuntimeNodeHttpEndpoint({
        endpoint: '/copilotkit',
        runtime,
        serviceAdapter: llmAdapter,
      });

      return handler(req, res, next);
    });

    app.listen(4000, () => {
      console.log('Listening at http://localhost:4000/copilotkit');
    });
    ```
  </Tabs.Tab>

  {/* Node.js HTTP */}
  <Tabs.Tab>
    Set up a simple Node.js HTTP server and use the Copilot Runtime to handle requests:

    ```ts filename="server.ts" showLineNumbers
    import { createServer } from 'node:http';
    import {
      CopilotRuntime,
      copilotRuntimeNodeHttpEndpoint,
    } from '@copilotkit/runtime';
    import llmAdapter from './src/lib/llmAdapter';

    const server = createServer((req, res) => {

      const runtime = new CopilotRuntime({
        remoteActions: [
          {
            url: `http://localhost:8000/copilotkit_remote`,
          }
        ]
      });

      const { handleRequest } = copilotRuntimeNextJSAppRouterEndpoint({
        runtime,
        serviceAdapter: llmAdapter,
        endpoint: '/copilotkit',
      });

      return handleRequest(req, res);
    });

    server.listen(4000, () => {
      console.log('Listening at http://localhost:4000/copilotkit');
    });
    ```
  </Tabs.Tab>

  {/* NestJS */}
  <Tabs.Tab>
    Set up a controller in NestJS to handle the Copilot Runtime endpoint:

    ```ts filename="copilotkit.controller.ts" showLineNumbers
    import { All, Controller, Req, Res } from '@nestjs/common';
    import { CopilotRuntime, OpenAIAdapter } from '@copilotkit/runtime';
    import llmAdapter from './src/lib/llmAdapter';

    @Controller()
    export class AppController {
      @All('/copilotkit')
      copilotkit(@Req() req: Request, @Res() res: Response) {

        const runtime = new CopilotRuntime({
          remoteActions: [
            {
              url: `http://localhost:8000/copilotkit_remote`,
            }
          ]
        });

        runtime.streamHttpServerResponse(req, res, llmAdapter);
      }
    }
    ```
  </Tabs.Tab>
</Tabs>


## Integrating agents into your CopilotKit frontend app

Once you've set up your agents and registered them with CopilotKit on the Python side, CopilotKit components in your frontend will **route** your users' interactions to the most appropriate agent. This default setting is called **router mode**.

Having set up our Next (or other) app's server route to work with the Python service, CopilotKit components should use your agents automatically:

```tsx filename="src/page.tsx"
// This UI will now invoke our AI agent, not just the LLM
<CopilotKit runtimeUrl="/api/copilotkit">
  <CopilotChat
    labels={{
      title: "Popup Assistant",
      initial: "Need any help?",
    }}
  />
</CopilotKit>
```

Any of CopilotKit's pre-built components can be used to interact with CoAgents, and you can also use agent-specific hooks in your custom UI components to enable powerful new workflows.








#### Optional: Enabling Agent Lock

Sometimes, you'll want a specific agent to run even before your users take action, to ensure that the user interacts with that agent right away.

For these scenarios, you can **lock** the UI to a specific agent in your CopilotKit frontend by passing in the `agent` prop. This is **agent lock mode**.

```tsx
<CopilotKit
  runtimeUrl="/api/copilotkit"
  agent="customer_service_agent"
>
```

For more details, see our documentation for [Router Mode and Agent Lock](/coagents/advanced-usage/router-mode-agent-lock).


#### Optional: Controlling agents programmatically

You might also want to start an agent programmatically. For this, you can use the `start`/`stop` functions returned by the `useCoAgent` hook:

```tsx
const { start, stop } = useCoAgent({ name: "car_rental_agent" });

start(); // stop();
```



### Agent Q&A

One of the key ways agents differ from normal chatbots is the ability to interrupt execution and ask for user feedback, using standard LangGraph mechanisms (interrupts, `__END__` node, etc.).

Most LangGraph agents should work out-of-the-box with CopilotKit, requiring only minimal configuration.

CoAgents receive the whole message history as context, even in nodes that are not directly exposed to the user, so they can take the user's feedback into account and provide precisely tailored actions and responses.

[Read more about agent Q&A](/coagents/feature-agent-qna)

<CoAgentsEnterpriseCTA />
